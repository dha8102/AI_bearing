{"cells":[{"cell_type":"markdown","metadata":{"id":"7e1yU7xYZ3Yq"},"source":["# [실습] 콘크리트 데이터셋을 활용한 예측 모델 실습\n","---"]},{"cell_type":"markdown","metadata":{"id":"eeaeasmtNjPd"},"source":["## 실습 목표\n","\n","- 실제로 수집된 콘크리트 배합 데이터셋에 다양한 머신러닝과 딥러닝 모델을 적용하여 콘크리트의 강도를 예측합니다.\n","\n","---"]},{"cell_type":"code","source":["!pip install numpy\n","!pip install pandas\n","!pip install matplotlib\n","!pip install seaborn\n","!pip install lightgbm\n","!pip install tensorflow"],"metadata":{"id":"4KVrcIAe1P-x"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"24E3eCmZNjPd"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# 이 코드는 불필요한 알림을 제거해주는 코드입니다.\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"ZKUrwS-eNjPr"},"source":["## 머신러닝을 활용한 콘크리트 강도 분석\n","이제 다양한 머신러닝을 활용하여 콘크리트의 강도를 예측해보겠습니다.\n","\n","먼저 데이터를 불러와서 독립변수와 종속변수를 설정해주어야 합니다. 종속변수란 우리가 예측해야 할 값이고, 독립변수란 종속변수를 예측하기 위해 사용하는 값들을 의미합니다. 여기에선 콘크리트 배합에 포함된 재료들의 양이 독립변수, 그에 따른 콘크리트의 강도가 종속변수가 될 것입니다. 콘크리트 데이터 전체가 담긴 `df`에서 \"Strength\" 컬럼을 제거한 나머지 컬럼들이 독립변수, \"Strength\"컬럼이 종속변수가 됩니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rNAX9dFwNjPr"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","df=pd.read_csv(\"concrete_data.csv\")\n","\n","# 독립 변수와 종속 변수 설정\n","X = df.drop('Strength', axis=1)\n","y = df['Strength']"]},{"cell_type":"markdown","metadata":{"id":"q2QnjU4VNjPr"},"source":["이제 전체 데이터를 학습 데이터와 테스트 데이터로 나누어야 합니다. 여러분이 학교 선생님이라고 생각해보세요. 학생들을 공부시키기 위한 문제들과, 학생들의 기말고사 시험문제는 철저히 분리되어야 합니다. 학생들을 공부시키기 위한 문제들(학습 데이터)로 공부 시킨다음, 기말고사 시험문제(테스트 데이터)로 역량을 평가해야 합니다. 인공지능도 마찬가지입니다. 인공지능 모델을 학습 데이터로 학습 시킨다음, 테스트 데이터로 평가해야 합니다.\n","\n","이렇게 둘을 나눈 이유는 인공지능에서 아주 중요한 **과적합**을 방지하기 위함입니다. 한 학생이 수학 문제집 단 한권만을 100번 풀었다고 가정해봅시다. 이제 그 학생은 이 문제집의 문제를 읽기만 해도 정답을 맞출 수 있을 정도로 학습이 되었을 것입니다. 하지만 과연 이 학생의 실제 수학 실력이 이렇게 좋을까요? 실제로 이 학생이 다른 문제집을 풀어도 잘 풀 수 있을까요?\n","\n","인공지능도 마찬가지입니다. 전체 데이터에 대해 학습을 해버리고 그 데이터로 평가까지 해버리면 인공지능은 해당 데이터에 철저히 맞춰버리므로(**과적합**) 당연히 평가지표가 좋게 나올 것입니다. 하지만 이 인공지능 모델은 해당 데이터만 잘 풀지 나머지 데이터는 엉망으로 풀어버릴 수도 있습니다. 평가지표가 의미가 없게 되어버리는 것입니다.\n","\n","이러한 상황을 방지하고자, 좀더 인공지능 모델의 성능을 직접적으로 확인하기 위해 학습 데이터셋과 테스트 데이터셋을 분리하여 사용하는 것입니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uV_NaISLNjPr"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# 학습 데이터와 테스트 데이터로 분할\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"gXPT9Es-NjPr"},"source":["인공지능 학습을 위한 데이터셋 분리까지 완료되었습니다. 이제 다양한 머신러닝 모델을 활용해보겠습니다.\n","\n","## 선형 회귀를 활용한 콘크리트 강도 분석\n","\n","선형 회귀(Linear Regression)는 종속 변수와 한 개 이상의 독립 변수 간의 관계를 모델링하는 데 사용되는 통계적 기법입니다. 주어진 데이터를 기반으로 독립 변수의 선형 조합을 통해 종속 변수를 예측하는 회귀 모델을 구축하는 것이 목표입니다.\n","![image.png](attachment:image.png)\n","\n","빨간색 점으로 된 데이터의 분포를 최대한 비슷하게 선으로 그린다고 생각하면 됩니다. 가령 키와 몸무게가 반드시 비례하는 것은 아니지만, 선을 그려보면 얼추 비슷한 선을 그릴 수 있을 것입니다.\n","\n","인공지능 관련된 다양한 기능이 담겨있는 `sklearn`라이브러리에서 선형 회귀 모델을 불러와 선형 회귀 분석을 해보겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YrTHkQP_NjPr","outputId":"0c5a93a8-c70f-4bf2-9804-bf488c25100f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean Squared Error: 95.97094009110681\n","Mean Absolute Error: 7.745559243921434\n"]}],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","# 선형 회귀 모델 학습\n","lr = LinearRegression()\n","lr.fit(X_train, y_train)\n","\n","# 테스트 데이터로 예측\n","y_pred = lr.predict(X_test)\n","\n","# 평가 지표 계산\n","mse = mean_squared_error(y_test, y_pred)\n","mae = mean_absolute_error(y_test, y_pred)\n","print(\"Mean Squared Error:\", mse)\n","print(\"Mean Absolute Error:\", mae)"]},{"cell_type":"markdown","metadata":{"id":"xAqEiX_pNjPr"},"source":["MSE는 Mean-Sqaured-Error의 약자로, 각 예측값과 실제값의 차이의 제곱을 평균값으로 정리한 것입니다.\n","MAE는 각 예측값과 실제값의 차이의 절대값을 평균값으로 정리한 것입니다.\n","\n","두 지표 모두 선형 회귀 분석에서 모델의 성능을 평가할 때 유용하게 활용됩니다. 각 지표가 활용되는 경우가 조금씩 다르지만 일단 이번 실습에서는 모두 측정해보도록 하곘습니다.\n","\n","이제 콘크리트 강도를 예측하는 인공지능 모델이 완성되었습니다. 한번 값을 넣어서 출력 결과를 확인해볼까요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hsgjhuCENjPr","outputId":"41a3a015-7470-489a-b26b-373a99385b1b"},"outputs":[{"data":{"text/plain":["array([93.1750445])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["lr.predict([[260.6, 144.4, 0.0, 196.0, 0.0, 909.4, 845.5, 560]])"]},{"cell_type":"markdown","metadata":{"id":"QLygr4o5NjPr"},"source":["시멘트를 많이 부었더니 강도가 아주 높은 콘크리트가 탄생했습니다. 이제 부자가 될 수 있겠군요.\n","\n","## SVM을 활용한 콘크리트 강도 분석\n","\n","이번엔 SVM이라는 머신러닝 모델을 활용해보겠습니다. SVM은 데이터 포인트들을 고차원 공간에 매핑하고, 서로 다른 클래스를 가장 잘 구분하는 경계를 찾는 것을 목표로 합니다. 즉 데이터를 뿌린 다음 데이터를 구분할 수 있는 가장 좋은 선을 긋는다고 생각하면 쉽습니다.\n","\n","![image.png](attachment:image.png)\n","\n","검은 점과 흰색 점을 구분하는 최적의 선을 그렸습니다.\n","\n","SVM은 물론 수치로된 값을 맞추는 회귀 분석에도 활용할 수 있지만, 이번에는 데이터를 조금 변형해서 콘크리트의 강도에 따라 활용도를 구분하는 분류 문제를 풀어보겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B48CxOkLNjPs","outputId":"5e785531-ec2a-4594-fbfa-94c31a52318d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cement</th>\n","      <th>Blast Furnace Slag</th>\n","      <th>Fly Ash</th>\n","      <th>Water</th>\n","      <th>Superplasticizer</th>\n","      <th>Coarse Aggregate</th>\n","      <th>Fine Aggregate</th>\n","      <th>Age</th>\n","      <th>use</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>540.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>162.0</td>\n","      <td>2.5</td>\n","      <td>1040.0</td>\n","      <td>676.0</td>\n","      <td>28</td>\n","      <td>Strong</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>540.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>162.0</td>\n","      <td>2.5</td>\n","      <td>1055.0</td>\n","      <td>676.0</td>\n","      <td>28</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>332.5</td>\n","      <td>142.5</td>\n","      <td>0.0</td>\n","      <td>228.0</td>\n","      <td>0.0</td>\n","      <td>932.0</td>\n","      <td>594.0</td>\n","      <td>270</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>332.5</td>\n","      <td>142.5</td>\n","      <td>0.0</td>\n","      <td>228.0</td>\n","      <td>0.0</td>\n","      <td>932.0</td>\n","      <td>594.0</td>\n","      <td>365</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>198.6</td>\n","      <td>132.4</td>\n","      <td>0.0</td>\n","      <td>192.0</td>\n","      <td>0.0</td>\n","      <td>978.4</td>\n","      <td>825.5</td>\n","      <td>360</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1025</th>\n","      <td>276.4</td>\n","      <td>116.0</td>\n","      <td>90.3</td>\n","      <td>179.6</td>\n","      <td>8.9</td>\n","      <td>870.1</td>\n","      <td>768.3</td>\n","      <td>28</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>1026</th>\n","      <td>322.2</td>\n","      <td>0.0</td>\n","      <td>115.6</td>\n","      <td>196.0</td>\n","      <td>10.4</td>\n","      <td>817.9</td>\n","      <td>813.4</td>\n","      <td>28</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>1027</th>\n","      <td>148.5</td>\n","      <td>139.4</td>\n","      <td>108.6</td>\n","      <td>192.7</td>\n","      <td>6.1</td>\n","      <td>892.4</td>\n","      <td>780.0</td>\n","      <td>28</td>\n","      <td>Dispose</td>\n","    </tr>\n","    <tr>\n","      <th>1028</th>\n","      <td>159.1</td>\n","      <td>186.7</td>\n","      <td>0.0</td>\n","      <td>175.6</td>\n","      <td>11.3</td>\n","      <td>989.6</td>\n","      <td>788.9</td>\n","      <td>28</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>1029</th>\n","      <td>260.9</td>\n","      <td>100.5</td>\n","      <td>78.3</td>\n","      <td>200.6</td>\n","      <td>8.6</td>\n","      <td>864.5</td>\n","      <td>761.5</td>\n","      <td>28</td>\n","      <td>Normal</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1030 rows × 9 columns</p>\n","</div>"],"text/plain":["      Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n","0      540.0                 0.0      0.0  162.0               2.5   \n","1      540.0                 0.0      0.0  162.0               2.5   \n","2      332.5               142.5      0.0  228.0               0.0   \n","3      332.5               142.5      0.0  228.0               0.0   \n","4      198.6               132.4      0.0  192.0               0.0   \n","...      ...                 ...      ...    ...               ...   \n","1025   276.4               116.0     90.3  179.6               8.9   \n","1026   322.2                 0.0    115.6  196.0              10.4   \n","1027   148.5               139.4    108.6  192.7               6.1   \n","1028   159.1               186.7      0.0  175.6              11.3   \n","1029   260.9               100.5     78.3  200.6               8.6   \n","\n","      Coarse Aggregate  Fine Aggregate  Age      use  \n","0               1040.0           676.0   28   Strong  \n","1               1055.0           676.0   28   Normal  \n","2                932.0           594.0  270   Normal  \n","3                932.0           594.0  365   Normal  \n","4                978.4           825.5  360   Normal  \n","...                ...             ...  ...      ...  \n","1025             870.1           768.3   28   Normal  \n","1026             817.9           813.4   28   Normal  \n","1027             892.4           780.0   28  Dispose  \n","1028             989.6           788.9   28   Normal  \n","1029             864.5           761.5   28   Normal  \n","\n","[1030 rows x 9 columns]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.svm import SVR\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","\n","df=pd.read_csv(\"concrete_data.csv\")\n","\n","def sep(strength):\n","    if strength > 70:\n","        return \"Strong\"\n","    elif 70 >= strength > 30:\n","        return \"Normal\"\n","    else:\n","        return \"Dispose\"\n","\n","df[\"use\"] = df[\"Strength\"].apply(sep)\n","df.drop(\"Strength\", axis=1, inplace=True)\n","\n","df"]},{"cell_type":"markdown","metadata":{"id":"yUerzqd9NjPs"},"source":["위의 코드를 활용해 콘크리트를 강도에 따라 \"Strong\", \"Normal\", \"Dispose\"로 분류하였습니다. 이제 SVM을 활용해 콘크리트를 분류해보겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jPT4IzuCNjPs","outputId":"bb37f36f-f69a-48f5-9f7c-1ad32fd4dbfd"},"outputs":[{"name":"stdout","output_type":"stream","text":["SVM 모델의 정확도:  77.67 %\n"]}],"source":["from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","X = df.drop(\"use\", axis=1)\n","y = df[\"use\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# SVM 모델 학습\n","svm = SVC()\n","svm.fit(X_train, y_train)\n","\n","# 테스트 데이터로 예측\n","y_pred = svm.predict(X_test)\n","\n","# 평가 지표 계산\n","acc = accuracy_score(y_test, y_pred)\n","print(\"SVM 모델의 정확도: \", round(acc*100,2), \"%\")"]},{"cell_type":"markdown","metadata":{"id":"YxAZcHOgNjPs"},"source":["분류 모델은 말그대로 예측결과가 실제 결과와 같은지 다른지를 비교할 수 있기 때문에 간단하게 정확도를 측정할 수 있습니다. SVM모델의 콘크리트 분류 정확도는 대략 77%가 나온 것을 확인할 수 있습니다.\n","\n","한번 더 값을 입력해서 결과를 출력해볼까요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c5bXSph2NjPs","outputId":"1e4fc79c-5430-4d2e-da2c-6aba9462dcd4"},"outputs":[{"data":{"text/plain":["array(['Dispose'], dtype=object)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["svm.predict([[196, 132, 0.0, 350.0, 0.0, 909.4, 845.5, 5]])"]},{"cell_type":"markdown","metadata":{"id":"kJw3GS4sNjPs"},"source":["이런, 이번 콘크리트는 폐기해야겠군요.\n","\n","SVM은 선형 분류 문제뿐만 아니라 비선형 문제에도 적용할 수 있습니다. 비선형 문제의 경우 커널 함수를 사용하여 데이터를 고차원 공간으로 매핑한 후 선형 분류를 수행합니다.\n","\n","SVM은 이론적으로 강력하며 일반화 성능이 좋은 모델입니다. 또한, 서포트 벡터를 기반으로 하기 때문에 학습 데이터에 영향을 크게 받지 않는다는 특징을 가지고 있습니다. SVM은 분류, 회귀, 이상치 탐지 등 다양한 문제에 적용되며, 특히 작은 데이터셋에서 성능이 우수합니다."]},{"cell_type":"markdown","metadata":{"id":"doOZfB2nNjPs"},"source":["## 앙상블 모델을 활용한 콘크리트 강도 분석\n","\n","집단지성이라는 말을 아시나요. 다수의 개체들이 서로 협력 혹은 경쟁을 통하여 얻게 되는 지적 능력에 의한 결과로 얻어진 집단적 능력을 뜻합니다. 그렇다면 인공지능도 여러개의 모델이 힘을 합치면 성능을 증가시킬 수 있지 않을까요?\n","\n","앙상블 기법은 이러한 생각에서 출발하여 만들어진 인공지능 기법입니다. 앙상블 기법은 다양한 모델을 결합하여 더 강력하고 안정적인 예측 모델을 구축하는 데 활용됩니다.\n","\n","대표적인 앙상블 기법, 그 중에서도 여러개의 약한 인공지능 모델들의 결과를 합쳐 최종 예측값을 만들어내는 부스팅 기법의 대표적인 모델인 LightGBM을 활용해 콘크리트의 강도 값을 예측해보겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"VdjUZnqmNjPs","outputId":"f0705fe7-ed04-4c6a-f4b5-e46b8c9672ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 973\n","[LightGBM] [Info] Number of data points in the train set: 824, number of used features: 8\n","[LightGBM] [Info] Start training from score 35.857864\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","Mean Squared Error: 21.997791727032897\n","Mean Absolute Error: 3.163961383428411\n"]}],"source":["import numpy as np\n","import pandas as pd\n","\n","import lightgbm as lgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","\n","df=pd.read_csv(\"concrete_data.csv\")\n","\n","# 독립 변수와 종속 변수 분리\n","X = df.drop('Strength', axis=1)\n","y = df['Strength']\n","\n","# 학습 데이터와 테스트 데이터로 분할\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# LightGBM 데이터셋 생성\n","train_data = lgb.Dataset(X_train, label=y_train)\n","\n","# LightGBM 모델 설정\n","params = {'objective': 'regression', 'metric': 'mse'}\n","lgbm = lgb.train(params, train_data)\n","\n","# 테스트 데이터로 예측\n","y_pred = lgbm.predict(X_test)\n","\n","# 예측 결과 평가\n","mse = mean_squared_error(y_test, y_pred)\n","mae = mean_absolute_error(y_test, y_pred)\n","print(\"Mean Squared Error:\", mse)\n","print(\"Mean Absolute Error:\", mae)"]},{"cell_type":"markdown","metadata":{"id":"ulJEEYacNjPt"},"source":["이렇게 머신러닝은 다양한 기법이 존재합니다.\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"cWppeYvmNjPt"},"source":["## 딥러닝을 활용한 콘크리트 강도 분석\n","\n","딥러닝(Deep Learning)은 인공신경망(Artificial Neural Network)을 기반으로 한 머신러닝 알고리즘의 한 종류입니다. 딥러닝은 다층 신경망(Multi-Layer Perceptron, MLP)을 사용하여 복잡한 문제를 해결하고 데이터로부터 의미 있는 특징을 추출하는 능력을 갖추고 있습니다. 사람의 뉴런처럼 연결된 여러개의 신경망이 수학적 연산을 통해 값을 출력합니다.\n","\n","![image.png](attachment:image.png)\n","\n","다층 신경망(MLP)은 입력층(input layer), 은닉층(hidden layer), 출력층(output layer) 등으로 구성된 인공신경망 구조입니다. 각 층은 여러 개의 뉴런 또는 노드로 구성되어 있으며, 각 뉴런은 가중치와 활성화 함수를 가지고 있습니다. 입력층은 데이터를 받아들이고, 은닉층은 중간 계산을 수행하고, 출력층은 최종 결과를 출력합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"79YCLrN-NjPt","outputId":"2c4a35d1-9d6f-4109-cae1-79e9d5c26923"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-07-20 15:42:55.207641: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-07-20 15:42:58.438963: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-07-20 15:43:18.170029: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-07-20 15:43:18.170953: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-07-20 15:43:18.171009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","\n","df=pd.read_csv(\"concrete_data.csv\")\n","\n","# 독립 변수와 종속 변수 분리\n","X = df.drop('Strength', axis=1)\n","y = df['Strength']\n","\n","# 학습 데이터와 테스트 데이터로 분할\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"PhKTaKoJNjPt"},"source":["학습 데이터와 테스트 데이터를 분리한 다음 MLP 모델을 구현해보겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-g2jtRNNjPt","outputId":"06805449-b4db-4d7e-de38-1bdc0eeeaafd"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-07-20 15:43:34.157783: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-07-20 15:43:34.159007: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n","2023-07-20 15:43:34.159080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (63f3dce37412): /proc/driver/nvidia/version does not exist\n","2023-07-20 15:43:34.161756: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 64)                576       \n","                                                                 \n"," dense_1 (Dense)             (None, 128)               8320      \n","                                                                 \n"," dense_2 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 17,217\n","Trainable params: 17,217\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# MLP 모델 구성\n","MLP = Sequential()\n","MLP.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n","MLP.add(Dense(128, activation='relu'))\n","MLP.add(Dense(64, activation='relu'))\n","MLP.add(Dense(1))\n","\n","MLP.summary()"]},{"cell_type":"markdown","metadata":{"id":"-1yVBgoBNjPt"},"source":["간단한 MLP 모델을 구현했습니다. 이제 데이터를 학습시켜 콘크리트 강도 예측 결과를 확인해보겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49Q9oTMwNjPt","outputId":"1dbe909e-66c1-486f-bd7e-63ad9df7d238"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","26/26 [==============================] - 2s 4ms/step - loss: 906.6160\n","Epoch 2/100\n","26/26 [==============================] - 0s 2ms/step - loss: 208.1891\n","Epoch 3/100\n","26/26 [==============================] - 0s 2ms/step - loss: 137.4408\n","Epoch 4/100\n","26/26 [==============================] - 0s 2ms/step - loss: 122.0249\n","Epoch 5/100\n","26/26 [==============================] - 0s 2ms/step - loss: 117.5061\n","Epoch 6/100\n","26/26 [==============================] - 0s 2ms/step - loss: 104.8951\n","Epoch 7/100\n","26/26 [==============================] - 0s 2ms/step - loss: 95.5374\n","Epoch 8/100\n","26/26 [==============================] - 0s 2ms/step - loss: 83.9863\n","Epoch 9/100\n","26/26 [==============================] - 0s 2ms/step - loss: 83.6128\n","Epoch 10/100\n","26/26 [==============================] - 0s 2ms/step - loss: 72.7194\n","Epoch 11/100\n","26/26 [==============================] - 0s 2ms/step - loss: 78.3516\n","Epoch 12/100\n","26/26 [==============================] - 0s 2ms/step - loss: 66.1147\n","Epoch 13/100\n","26/26 [==============================] - 0s 2ms/step - loss: 65.4475\n","Epoch 14/100\n","26/26 [==============================] - 0s 2ms/step - loss: 76.6917\n","Epoch 15/100\n","26/26 [==============================] - 0s 2ms/step - loss: 57.0745\n","Epoch 16/100\n","26/26 [==============================] - 0s 2ms/step - loss: 55.4550\n","Epoch 17/100\n","26/26 [==============================] - 0s 2ms/step - loss: 54.4260\n","Epoch 18/100\n","26/26 [==============================] - 0s 2ms/step - loss: 51.9736\n","Epoch 19/100\n","26/26 [==============================] - 0s 2ms/step - loss: 57.7102\n","Epoch 20/100\n","26/26 [==============================] - 0s 2ms/step - loss: 68.4579\n","Epoch 21/100\n","26/26 [==============================] - 0s 2ms/step - loss: 50.9866\n","Epoch 22/100\n","26/26 [==============================] - 0s 2ms/step - loss: 47.0448\n","Epoch 23/100\n","26/26 [==============================] - 0s 2ms/step - loss: 45.6051\n","Epoch 24/100\n","26/26 [==============================] - 0s 2ms/step - loss: 48.9120\n","Epoch 25/100\n","26/26 [==============================] - 0s 2ms/step - loss: 48.3242\n","Epoch 26/100\n","26/26 [==============================] - 0s 2ms/step - loss: 53.8524\n","Epoch 27/100\n","26/26 [==============================] - 0s 2ms/step - loss: 59.8874\n","Epoch 28/100\n","26/26 [==============================] - 0s 2ms/step - loss: 48.1204\n","Epoch 29/100\n","26/26 [==============================] - 0s 2ms/step - loss: 49.4490\n","Epoch 30/100\n","26/26 [==============================] - 0s 2ms/step - loss: 44.3615\n","Epoch 31/100\n","26/26 [==============================] - 0s 2ms/step - loss: 49.2114\n","Epoch 32/100\n","26/26 [==============================] - 0s 2ms/step - loss: 50.1311\n","Epoch 33/100\n","26/26 [==============================] - 0s 2ms/step - loss: 39.8163\n","Epoch 34/100\n","26/26 [==============================] - 0s 2ms/step - loss: 44.6040\n","Epoch 35/100\n","26/26 [==============================] - 0s 2ms/step - loss: 46.9406\n","Epoch 36/100\n","26/26 [==============================] - 0s 2ms/step - loss: 38.4112\n","Epoch 37/100\n","26/26 [==============================] - 0s 2ms/step - loss: 39.8138\n","Epoch 38/100\n","26/26 [==============================] - 0s 2ms/step - loss: 44.2989\n","Epoch 39/100\n","26/26 [==============================] - 0s 2ms/step - loss: 48.9832\n","Epoch 40/100\n","26/26 [==============================] - 0s 2ms/step - loss: 39.6343\n","Epoch 41/100\n","26/26 [==============================] - 0s 2ms/step - loss: 39.7671\n","Epoch 42/100\n","26/26 [==============================] - 0s 2ms/step - loss: 37.7297\n","Epoch 43/100\n","26/26 [==============================] - 0s 2ms/step - loss: 42.7634\n","Epoch 44/100\n","26/26 [==============================] - 0s 2ms/step - loss: 66.9012\n","Epoch 45/100\n","26/26 [==============================] - 0s 2ms/step - loss: 64.4113\n","Epoch 46/100\n","26/26 [==============================] - 0s 2ms/step - loss: 46.8645\n","Epoch 47/100\n","26/26 [==============================] - 0s 2ms/step - loss: 44.2647\n","Epoch 48/100\n","26/26 [==============================] - 0s 2ms/step - loss: 38.9039\n","Epoch 49/100\n","26/26 [==============================] - 0s 2ms/step - loss: 45.6562\n","Epoch 50/100\n","26/26 [==============================] - 0s 2ms/step - loss: 47.2419\n","Epoch 51/100\n","26/26 [==============================] - 0s 2ms/step - loss: 37.9285\n","Epoch 52/100\n","26/26 [==============================] - 0s 2ms/step - loss: 43.2251\n","Epoch 53/100\n","26/26 [==============================] - 0s 2ms/step - loss: 36.1462\n","Epoch 54/100\n","26/26 [==============================] - 0s 2ms/step - loss: 39.9783\n","Epoch 55/100\n","26/26 [==============================] - 0s 2ms/step - loss: 38.4721\n","Epoch 56/100\n","26/26 [==============================] - 0s 2ms/step - loss: 38.3773\n","Epoch 57/100\n","26/26 [==============================] - 0s 2ms/step - loss: 36.8480\n","Epoch 58/100\n","26/26 [==============================] - 0s 2ms/step - loss: 44.2247\n","Epoch 59/100\n","26/26 [==============================] - 0s 2ms/step - loss: 40.7197\n","Epoch 60/100\n","26/26 [==============================] - 0s 2ms/step - loss: 39.3943\n","Epoch 61/100\n","26/26 [==============================] - 0s 2ms/step - loss: 34.6479\n","Epoch 62/100\n","26/26 [==============================] - 0s 2ms/step - loss: 35.0475\n","Epoch 63/100\n","26/26 [==============================] - 0s 2ms/step - loss: 35.6804\n","Epoch 64/100\n","26/26 [==============================] - 0s 2ms/step - loss: 33.5457\n","Epoch 65/100\n","26/26 [==============================] - 0s 2ms/step - loss: 36.5311\n","Epoch 66/100\n","26/26 [==============================] - 0s 2ms/step - loss: 43.0914\n","Epoch 67/100\n","26/26 [==============================] - 0s 2ms/step - loss: 38.5728\n","Epoch 68/100\n","26/26 [==============================] - 0s 2ms/step - loss: 34.4954\n","Epoch 69/100\n","26/26 [==============================] - 0s 2ms/step - loss: 35.1575\n","Epoch 70/100\n","26/26 [==============================] - 0s 2ms/step - loss: 31.8281\n","Epoch 71/100\n","26/26 [==============================] - 0s 2ms/step - loss: 34.8277\n","Epoch 72/100\n","26/26 [==============================] - 0s 2ms/step - loss: 31.9958\n","Epoch 73/100\n","26/26 [==============================] - 0s 2ms/step - loss: 38.8762\n","Epoch 74/100\n","26/26 [==============================] - 0s 2ms/step - loss: 40.9477\n","Epoch 75/100\n","26/26 [==============================] - 0s 2ms/step - loss: 50.3897\n","Epoch 76/100\n","26/26 [==============================] - 0s 2ms/step - loss: 55.3380\n","Epoch 77/100\n","26/26 [==============================] - 0s 2ms/step - loss: 37.8816\n","Epoch 78/100\n","26/26 [==============================] - 0s 2ms/step - loss: 39.4907\n","Epoch 79/100\n","26/26 [==============================] - 0s 2ms/step - loss: 43.9653\n","Epoch 80/100\n","26/26 [==============================] - 0s 2ms/step - loss: 37.7275\n","Epoch 81/100\n","26/26 [==============================] - 0s 2ms/step - loss: 35.6761\n","Epoch 82/100\n","26/26 [==============================] - 0s 2ms/step - loss: 32.8983\n","Epoch 83/100\n","26/26 [==============================] - 0s 2ms/step - loss: 40.1293\n","Epoch 84/100\n","26/26 [==============================] - 0s 2ms/step - loss: 31.0921\n","Epoch 85/100\n","26/26 [==============================] - 0s 2ms/step - loss: 32.3814\n","Epoch 86/100\n","26/26 [==============================] - 0s 2ms/step - loss: 32.0297\n","Epoch 87/100\n","26/26 [==============================] - 0s 2ms/step - loss: 37.4232\n","Epoch 88/100\n","26/26 [==============================] - 0s 2ms/step - loss: 35.9482\n","Epoch 89/100\n","26/26 [==============================] - 0s 2ms/step - loss: 29.4241\n","Epoch 90/100\n","26/26 [==============================] - 0s 2ms/step - loss: 31.3497\n","Epoch 91/100\n","26/26 [==============================] - 0s 2ms/step - loss: 34.6157\n","Epoch 92/100\n","26/26 [==============================] - 0s 2ms/step - loss: 32.1840\n","Epoch 93/100\n","26/26 [==============================] - 0s 2ms/step - loss: 30.3096\n","Epoch 94/100\n","26/26 [==============================] - 0s 2ms/step - loss: 32.3269\n","Epoch 95/100\n","26/26 [==============================] - 0s 2ms/step - loss: 34.5282\n","Epoch 96/100\n","26/26 [==============================] - 0s 2ms/step - loss: 38.3405\n","Epoch 97/100\n","26/26 [==============================] - 0s 2ms/step - loss: 48.4233\n","Epoch 98/100\n","26/26 [==============================] - 0s 2ms/step - loss: 36.2484\n","Epoch 99/100\n","26/26 [==============================] - 0s 2ms/step - loss: 30.3032\n","Epoch 100/100\n","26/26 [==============================] - 0s 2ms/step - loss: 32.0945\n","7/7 [==============================] - 0s 2ms/step\n","Mean Squared Error: 37.56516010614935\n","Mean Absolute Error: 4.812228833818899\n"]}],"source":["# 모델 컴파일\n","MLP.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# 모델 학습\n","MLP.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n","\n","# 테스트 데이터로 예측\n","y_pred = MLP.predict(X_test)\n","\n","# 예측 결과 평가\n","mse = mean_squared_error(y_test, y_pred)\n","mae = mean_absolute_error(y_test, y_pred)\n","print(\"Mean Squared Error:\", mse)\n","print(\"Mean Absolute Error:\", mae)"]},{"cell_type":"markdown","metadata":{"id":"gxN5HkydNjPt"},"source":["총 100번의 학습(epochs)를 수행하여 최종적으로 콘크리트의 강도를 예측하는 딥러닝 모델을 완성하였습니다.\n","\n","---\n","\n","지금까지 콘크리트 데이터셋을 활용한 데이터 분석부터 머신러닝, 딥러닝 모델을 활용한 예측까지를 수행해보았습니다. 물론 오늘 배운 내용이 전부는 아닙니다. 오늘은 아무것도 건드리지 않은 인공지능 모델들을 활용했지만, 인공지능 모델의 성능을 향상시키는데에는 다양한 방법이 존재합니다.\n","\n","하이퍼파라미터는 모델의 성능에 큰 영향을 미치는 매개 변수들로, 이들을 조정하여 모델을 튜닝할 수 있습니다. 또한, 다양한 인공지능 기법들을 적용함으로써 더 강력하고 효율적인 모델을 개발할 수 있습니다.\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"fZMiluOyNjPt"},"source":["<span style=\"color:rgb(120, 120, 120)\">본 학습 자료를 포함한 사이트 내 모든 자료의 저작권은 엘리스에 있으며 외부로의 무단 복제, 배포 및 전송을 불허합니다.\n","\n","Copyright @ elice all rights reserved</span>"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}